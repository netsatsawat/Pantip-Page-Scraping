{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading: http://pantip.com/topic/30000100.html\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "Now reading: http://pantip.com/topic/30000200.html\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "# Name: Pantip Scraping \n",
    "# Description: Get post date, link, topic name, and tags\n",
    "# Version:\n",
    "#   09/20/2016 SN: Initial version\n",
    "#   09/21/2016 SN: Update to handle and skip either missing page or deleted page\n",
    "####################################################################################\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from lxml import html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_pantip_scrape(df, s):\n",
    "    page_init = 30000000\n",
    "    page_num = page_init + s\n",
    "    site = \"http://pantip.com/topic/\"+ str(page_num) + \".html\"\n",
    "    if s%100 == 0:\n",
    "        print(\"Now reading: \" + site)\n",
    "    response = urlopen(site)\n",
    "    html = response.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    notFoundPage = len(re.findall('ไม่พบหน้าที่คุณต้องการ',html))\n",
    "    deletePage = len(re.findall('เจ้าของข้อความแจ้งลบค่ะ', html))\n",
    "    print(notFoundPage, deletePage)\n",
    "    if notFoundPage == 0 and deletePage == 0:\n",
    "        # Get topic create time\n",
    "        tmp_post_time = soup.find(\"abbr\", class_=\"timeago\")\n",
    "        post_time_list = re.findall(r'(?<=data-utime=\\\")[^\\\"]*', str(tmp_post_time))\n",
    "        # Get header; alternatively can use soup.title.contents\n",
    "        title_list = soup.find(\"h2\", class_=\"display-post-title\").contents\n",
    "        # Get page tags\n",
    "        tag_list =[]\n",
    "        for tag in soup.findAll(\"a\", {\"class\" : \"tag-item\"} ):\n",
    "            tmp_tag = tag.contents\n",
    "            tmp_tag_str = str(tmp_tag)\n",
    "            tmp_tag_str = tmp_tag_str.strip(\"['']\")\n",
    "            tag_list.append(tmp_tag_str)\n",
    "        tag_list = list(set(tag_list))\n",
    "\n",
    "        df2 = pd.DataFrame( {'a_index': s,\n",
    "                             'url' : site,\n",
    "                            'title': title_list,\n",
    "                            'create_time' : post_time_list,\n",
    "                            })   \n",
    "        df2.ix[df.index.get_values(), 'tag'] = ', '.join(tag_list)\n",
    "        df = df.append(df2)\n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "columns = ['create_time', 'title', 'url', 'tag']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df = df.fillna(0)\n",
    "for i in range(100,1000):\n",
    "    df = get_pantip_scrape(df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"pantip_scraping.csv\", sep= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "101 %100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
